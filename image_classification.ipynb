{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport tensorflow as tf\nimport numpy as np\nimport json\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Directories Variables"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"root_dir = '/kaggle/input/artificial-neural-networks-and-deep-learning-2020/MaskDataset'\n\ntrain_gt = '%s/train_gt.json' % root_dir\ntraining_dir = '%s/training' % root_dir\n\ntesting_dir = '%s/test' % root_dir\n\noutput_dir = '/kaggle/working'\n\ntrain_faces_gt = '%s/train_faces_gt.json' % output_dir\ntraining_faces_dir = '%s/training_faces' % output_dir","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install retinaface --quiet\nfrom retinaface import RetinaFace\n\nfrom PIL import Image\n\n!pip install tensorflow --upgrade --quiet","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Faces Cropping"},{"metadata":{"trusted":true},"cell_type":"code","source":"face_detector = RetinaFace(quality='normal')\n\ndef crop_faces_from_images(dataframe):\n    faces = []\n    for index, img in dataframe.loc[(dataframe['class'] == 0) | (dataframe['class'] == 1)].iterrows():\n\n        img_path = \"{}/{}\".format(training_dir, img['filename'])\n        \n        rgb_img = Image.open(img_path).convert('RGB')\n        img_pixels = np.asarray(rgb_img)\n\n        img_faces = face_detector.predict(img_pixels)\n\n        img_w, img_h = rgb_img.size\n\n        for face_index, face in enumerate(img_faces):\n            x1, x2 = face['x1'], face['x2']\n            y1, y2 = face['y1'], face['y2']\n            x1, x2, y1, y2 = max(0, x1), min(x2, img_w), max(0, y1), min(y2, img_h)\n\n            cropped_img = rgb_img.crop((x1,y1,x2,y2))\n            \n            face_name = \"face%d_%s\" % (face_index, img['filename'])\n            face_path = \"%s/%s\" % (training_faces_dir, face_name)\n\n            faces.append({\"image\": cropped_img, \"path\": face_path,\n                         \"filename\": face_name, \"class\": \"mask\" if img['class']==1 else \"no_mask\"})\n    \n    return faces\n\ndef save_training_faces(faces):\n    if not os.path.isdir(training_faces_dir):\n        os.mkdir(training_faces_dir)\n        \n    for face in faces:\n        cropped_img = face['image']\n        face_path = face['path']\n        \n        cropped_img.save(face_path)\n\ndef load_training_dataframe():\n    if os.path.isfile(train_faces_gt):\n        return pd.read_json(train_faces_gt)\n    \n    with open(train_gt) as f:\n        dic = json.load(f)\n        f.close()\n\n    dataframe = pd.DataFrame(dic.items())\n    dataframe.rename(columns = {0:'filename', 1:'class'}, inplace = True)\n    \n    faces = crop_faces_from_images(dataframe)\n    save_training_faces(faces)\n    \n    faces_data = [[face['filename'], face['class']] for face in faces]\n    faces_dataframe = pd.DataFrame(faces_data, columns=['filename', 'class'])\n    faces_dataframe.to_json(train_faces_gt)\n    \n    return faces_dataframe","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Clean output folder"},{"metadata":{"trusted":true},"cell_type":"code","source":"clean_output_folder = False\n\nif clean_output_folder:\n    import shutil\n\n    if os.path.isdir(training_faces_dir):\n        shutil.rmtree(training_faces_dir)\n    if os.path.isfile(train_faces_gt):\n        os.remove(train_faces_gt)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Datasets Preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe = load_training_dataframe()\n\nprobs = np.random.rand(len(dataframe))\ntraining_mask = probs < 0.8\nvalidation_mask = probs>=0.8\n\ntraining_dataframe = dataframe[training_mask]\nvalidation_dataframe = dataframe[validation_mask]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Datasets Generation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define Variables\nclasses = ['mask', 'no_mask']\nnum_classes = len(classes) if classes!=None else 0\n\nimg_size = (112,112)\ninput_shape = (img_size[0], img_size[1], 3)\noutput_shapes = ([None, img_size[0], img_size[1], 3], [None])\n\nbatch_size = 100\n\nSEED = 1000\ntf.random.set_seed(SEED) \n\n#Training\ntrain_data_gen = ImageDataGenerator(rotation_range=10,\n                                    width_shift_range=10,\n                                    height_shift_range=10,\n                                    zoom_range=0.1,\n                                    shear_range=0.1,\n                                    channel_shift_range=0.1,\n                                    horizontal_flip=True,\n                                    vertical_flip=True,\n                                    fill_mode='constant',\n                                    rescale=1./255)\n\ntraining_generator = train_data_gen.flow_from_dataframe(training_dataframe,\n                                                        training_faces_dir,\n                                                        batch_size=batch_size,\n                                                        class_mode='binary',\n                                                        shuffle=True,\n                                                        seed=SEED,\n                                                        target_size=img_size,\n                                                        classes=classes)\n\ntraining_dataset = tf.data.Dataset.from_generator(lambda: training_generator,\n                                                  output_types=(tf.float32, tf.float32),\n                                                  output_shapes=output_shapes)\n\ntraining_dataset = training_dataset.repeat()\n\n# Validation\nval_data_gen = ImageDataGenerator(rescale=1./255)\n\nvalidation_generator = val_data_gen.flow_from_dataframe(validation_dataframe,\n                                                        training_faces_dir,\n                                                        batch_size=batch_size,\n                                                        class_mode='binary',\n                                                        shuffle=True,\n                                                        seed=SEED,\n                                                        target_size=img_size,\n                                                        classes=classes)\n\nvalidation_dataset = tf.data.Dataset.from_generator(lambda: validation_generator, \n                                                    output_types=(tf.float32, tf.float32),\n                                                    output_shapes=output_shapes)\n\nvalidation_dataset = validation_dataset.repeat()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Creation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transfer Learning Convolution\nvgg16 = tf.keras.applications.vgg16.VGG16(\n    input_shape=input_shape,\n    include_top=False,\n    weights=\"imagenet\",\n    classes=num_classes\n)\nvgg16.trainable = True\nfor layer in vgg16.layers:\n    if layer.name in ['block4_conv1', 'block5_conv1']:\n        layer.trainable = True\n    else:\n        layer.trainable = False\n\n# Classifier\nmodel = tf.keras.Sequential()\nmodel.add(vgg16)\n\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(units=128, activation='relu',  input_dim=input_shape))\nmodel.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Optimization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# learning rate\nlearning_rate = 1e-5\noptimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n\n# Loss\nloss = tf.keras.losses.BinaryCrossentropy()\n\n# Validation metrics\nmetrics = ['accuracy']\n\n# Compile Model\nmodel.compile(optimizer=optimizer, loss=loss, metrics=metrics)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Early Stopping\nes_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\ncallbacks = [es_callback]\n\nmodel.fit(training_dataset,\n          epochs=20,  #### set repeat in training dataset\n          steps_per_epoch=len(training_generator),\n          validation_data=validation_dataset,\n          validation_steps=len(validation_generator), \n          callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Testing Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ntest_images = [filename for filename in next(os.walk(testing_dir))[2]]\n\nresults={}\nfor index, img_filename in enumerate(test_images):\n    img_path = \"%s/%s\" % (testing_dir, img_filename)\n\n    rgb_img = Image.open(img_path).convert('RGB')\n    img_pixels = np.asarray(rgb_img)\n\n    img_faces = face_detector.predict(img_pixels)\n\n    img_w, img_h = rgb_img.size\n\n    faces_preds = []\n    for face_index, face in enumerate(img_faces):\n        x1, x2 = face['x1'], face['x2']\n        y1, y2 = face['y1'], face['y2']\n        x1, x2, y1, y2 = max(0, x1), min(x2, img_w), max(0, y1), min(y2, img_h)\n\n        cropped_img = rgb_img.crop((x1,y1,x2,y2))\n\n        face_test = cropped_img.resize(img_size, Image.ANTIALIAS)\n        face_test = tf.keras.preprocessing.image.img_to_array(face_test) / 255.0\n        face_test = np.expand_dims(face_test, axis=0)\n        \n        face_pred = model.predict(face_test)\n        face_pred = 1 if face_pred < 0.5 else 0\n        \n        faces_preds.append(face_pred)\n    \n    if sum(faces_preds) == 0:\n        img_pred = 0\n    elif sum(faces_preds) == len(img_faces):\n        img_pred = 1\n    else:\n        img_pred = 2\n    \n    results[img_filename] = img_pred\n    \n    if index % 50 == 0:\n        plt.figure()\n        plt.imshow(rgb_img)\n        plt.xlabel(faces_preds)\n        plt.title(\"First %d images analysed.\" % index)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create CSV"},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv\nfrom datetime import datetime\n\ndef create_csv(results, results_dir='./'):\n\n    for file in next(os.walk(output_dir))[2]:\n        if 'results' in file:\n            os.remove('%s/%s' % (output_dir, file))\n            \n    csv_fname = 'results_'\n    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n\n    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n\n        f.write('Id,Category\\n')\n\n        for key, value in results.items():\n            f.write(key + ',' + str(value) + '\\n')\n\ncreate_csv(results)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}